# 통계학 1주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_1st_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

1주차는 `1부. 데이터 기초체력 기르기`를 읽고 새롭게 배운 내용을 정리해주시면 됩니다.


## Statistics_1st_TIL

### 1부. 데이터 기초체력 기르기
### 01. 통계학 이해하기
### 02. 모집단과 표본추출
### 03. 변수와 척도
### 04. 데이터의 기술 통계적 측정
### 05. 확률과 확률변수

## Study Schedule

|주차 | 공부 범위     | 완료 여부 |
|----|----------------|----------|
|1주차| 1부 p.2~56     | ✅      |
|2주차| 1부 p.57~79    | 🍽️      | 
|3주차| 2부 p.82~120   | 🍽️      | 
|4주차| 2부 p.121~202  | 🍽️      | 
|5주차| 2부 p.203~254  | 🍽️      | 
|6주차| 3부 p.300~356  | 🍽️      | 
|7주차| 3부 p.357~615  | 🍽️      | 

<!-- 여기까진 그대로 둬 주세요-->

# 01. 통계학 이해하기

```
✅ 학습 목표 :
* 통계학의 필요성에 대해 인식한다.
* 기술통계와 추론통계의 특성을 구분할 수 있다.
```
<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->
### 1.1 왜 통계학을 알아야 할까?
---
데이터 과학은 기초 통계로부터 발전 
→ 통계 이론에 기반한 해석이 필수적

#### 🔍 데이터 과학의 전체 프로세스 
```
1. 데이터 수집
2. 데이터 가공
3. 탐색적 데이터 분석 & 데이터 시각화
4. M/L 모델링
5. 결과 해석 및 적용
```

### 1.2 머신러닝과 전통적 통계학의 차이
---
머신러닝의 주 목적은 예측<br>
→ 분석 모형의 복잡성이 높으며, 과적합 해결에 집중

 통계학의 주 목적은 해석(확률을 통해 가설을 검증하고 추정 모델을 통해 데이터 해석)<br>
 → 모델의 신뢰도를 중시하며 단순성을 추구, 각 변수의 영향력에 대한 해설과 모집단에서 추출한 샘플의 가정과 통계적 적합성에 집중

 #### 🔍 전통적 통계학과 머신러닝의 차이

 |  |통계학|머신러닝|
 | --- |---|---|
 |접근 방식|확률변수를 통해 자료생성과정을 파악|알고리즘 모델을 생성|
 |기반|수학, 이론|비선형 데이터 피팅|
 |목표|가설 점정, 현상 해석|예측 정확도 향상|
 |변수(차원)|10개 이하의 소수 변수 활용|다차원의 변수 활용|
 |활용|과거와 현재 데이터를 활용한 현상의 해석|과거와 현재 데이터를 활용한 미래 예측|
 |접근 방향|가설 → 데이터|데이터 → 가설|

### 1.3 통계학의 정의와 기원
---
통게학은 자료를 수집, 분석하여 그 분석 결과를 통해 효율적인 의사결정을 하는 기법을 연구하는 학문

### 1.4 기술 통계와 추론 통계
---

- 기술 통계<br>
    - 문자 그대로 주어진 데이터의 특성을 사실에 근거하여 설명하고 묘사하는 것
    - 가장 기본적인 방법: 대푯값을 설명하는 것
    - 기술 통계를 내는 것을 EDA라고 한다.
    - 보통 시각화를 많이 사용

- 추론 통계<br>
    - 표본으로 구한 통계량(statistic)을 이용해 모집단의 모수(parameter)를 추정하고, 신뢰구간을 계산하는 것

#### 🔍 기술 통계와 추론 통계의 통합적인 프로세스
```
표본의 특성 분석 → 특성의 일반화 여부 판단 →  모집단의 특성으로 추정
```

# 02. 모집단과 표본추출

```
✅ 학습 목표 :
* 모집단과 표본의 정의와 관계를 설명할 수 있다.
* 편향과 분산의 차이를 설명할 수 있다.
```

<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->

### 2.1 모집단과 표본, 전수조사와 표본조사   
---
- 모집단: 분석 대상 전체의 집단
- 표본: 모집단의 부분집합, 즉 모집단의 일부를 추출한 것 
- 전수조사: 모집단의 자료 전체를 조사 및 분석하여 정보를 추출하는 것
- 표본조사: 모집단에서 추출한 표본을 통해 모집단의 정보(평균, 표준편차 등)를 추정하고 검정하는 것    
### 2.2 표본조사를 하는 이유와 데이터과학 적용 방법
---
- 표본조사를 하는 이유
    - 분석 모델이 완성될 때까지는 표본 데이터를 활용하는 것이 경제적, 시간적으로 유리하기 때문.
- 데이터과학 적용 방법
    1. 예측 및 분류 모델링 단계
    - 적절한 표본을 추출하여 진행
    2. 전체 프로세스 완성 후
    - 전체 데이터를 사용하여 모델 성능을 확인하고 예측 및 분류하기

#### 🔍 기술 통계와 추론 통계의 통합적인 프로세스
```
1. 표본추출
2. 데이터 전처리 및 M/L 프로세스 개발
3. 전수 데이터 가공
4. 최종 모델 검증 및 예측
```

#### 표지-재포획법
- 표본조사를 통해 모집단의 크기를 추정하는 방법

    $\hat{N} = \dfrac{M \times n}{m}$
- $\hat{N}$ : 모집단의 추정 크기  
- $M$ : 1차 포획 후 표식한 개체 수  
- $n$ : 2차 포획 개체 수  
- $m$ : 2차 포획 중 표식된 개체 수

### 2.3 표본추출에서 나타나는 편향의 종류
---
- 표본 오차: 모집단과 표본의 자연 발생적인 변동   
→ 같은 크기의 두 개의 표본을 주의해서 추출한다고 해도 완전히 동일한 표본을 얻는 것은 불가능함
    - 우연, 표본 수의 부족, ....

- 비표본 오차: 표본 오차를 제외한 변동   
    - 편향, 조사원의 미숙, 자료의 그릇된 해석, ...

#### 🔍표본 추출 과정에서 발생하는 편향
```
1. 표본추출편향
  -  표본 추출 과정에서 체계적인 경향이 개입되어 모집단에서 편향된 표본만 추출되는 경우
2. 가구편향
  - 모집단의 부분 집단 단위에서 하나의 관측치씩 추출하는 경우 크고 적은 집단이 작고 많은 집단보다 적게 추출되는 경우
3. 무응답편향
  - 설문에 응답하지 않는 사람들과 응답하는 사람들에 체계적인 차이가 있는 경우
4. 응답편향
  - 설문 형식의 문제, 응답자의 심리적 이슈에 의해 표본이 영향을 받는 경우
```
#### 🔍 브래들리 효과
- 피조사자가 자신의 생각이나 신념을 밝히기 어려워하여 거짓된 응답을 하는 현상

- 확률화: 모집단으로부터 편향이 발생하지 않는 표본을 추출하는 방법
    - 확률표본: 확률화를 통해 추출한 표본
    - 확률추출: 모집단에서 표본이 추출될 확률이 동등한 추출
    - 비확률추출: 모집단에서 표본이 추출될 확률이 동등하지 않은 추출
    - 복원추출: 모집단에서 이미 추출한 표본을 다시 모집단에 되돌려 놓는 추출
    - 비복원추출: 모집단에서 이미 추출한 표본을 다시 모집단에 되돌려 놓지 않는 추출
### 2.4 인지적 편향의 종류
---
- 인지적 편향: 사람들은 언제나 합리적으로 생각하고 행동하는 것이 아니며, 휴리스틱을 통해 왜곡된 지각으로 결정을 하는 경우가 많다.
    - 확증 편향: 자신이 본래 믿고 있는 대로 정보를 선택적으로 받아들이고 임의로 판단하는 편향
    - 기준점 편향: 가장 처음에 접하는 정보에 지나치게 매몰되는 편향
    - 선택 지원 편향: 의사결정을 내리는 순간 그 선택의 긍정적인 부분에 대해 더 많이 생각하고 그 결정에 반대되는 증거를 무시하게 되는 편향
    - 분모 편향: 분수 전체가 아닌 분자에만 집중하여 현황을 왜곡하여 판단하게 되는 편향
    - 생존자 편향: 소수의 성공한 사례를 일반화된 것으로 인식함으로써 나타나는 편향

### 2.5 머신러닝 모델 측면의 편향과 분산
---
- 편향: 예측값들이 정답과 일정하게 차이가 나는 정도
- 분산: 주어진 데이터 포인트(평균 등)에 대한 모델 예측의 가변성

#### 🔍 편향과 분산은 트레이드오프 관계
```
모델이 단순할 때 → Bias(편향) 높고 Variance(분산) 낮음
 - 너무 단순하면 복잡한 패턴을 못 잡아서 Bias ↑
 - 근데 구조가 단순하니 데이터 변화에 크게 흔들리지 않음 → Variance ↓

모델이 복잡할 때 → Bias 낮고 Variance 높아
 - 복잡한 구조가 데이터 패턴까지 다 외워버려서 Bias ↓
 - 근데 작은 변화에도 과하게 반응 → Variance ↑
```
### 2.6 표본 편향을 최소화하기 위한 표본 추출 방법
---
- 표본추출의 두 가지 종류
    - 데이터 수집 단계의 표본 추출
    - 빅데이터에서 분석 모델링을 위한 적절한 크기의 표본데이터 추출
#### 🔍 표본추출 단계 구성
```
1. 모집단 확정
2. 표본 프레임 결정
3. 표본 추출방법 결정 # 확률표본추출과 비확률표본추출, 복원과 비복원 추출 중 적절한 방법 선택
4. 표본크기 결정
5. 표본추출
```
#### 🔍 확률 표본추출방법 종류
```
1. 단순 임의 추출방법
2. 계층적 표본추출방법
3. 층화 표본추출방법
4. 군집 표본추출방법
5. 복원추출
6. 비복원추출
```
# 03. 변수와 척도
```
✅ 학습 목표 :
* 독립변수, 종속변수의 관계를 파악할 수 있다.
* 척도(변수의 데이터적 속성)의 종류를 설명할 수 있다.
```
<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->

### 3.1 변수의 종류
---
- 변수:  값이 변할 수 있는 데이터를 저장하는 이름이나 공간

- 양적 변수: 계량적 변수
    - 이산변수: 정숫값만 취할 수 있는 변수
    - 연속변수: 연속적인 모든 실숫값을 취할 수 있는 변수
- 질적 변수: 비계량적 변수

- 독립변수(원인)
    - 설명변수
    - 입력변수
    - 예측변수
    - 조직변수
    - 특징(특히 머신러닝에선 feature)
    - 독립변수 간에는 상관관계가 없어야 한다.

- 종속변수(결과)
    - 반응변수
    - 출력변수
    - 피예측변수
    - 측정변수
    - 표적변수(target)

- 독립변수와 종속변수는 기본적으로 서로 상관관계를 가진다.
    
- 통제변수: 종속변수에 영향을 줄 수 있는 외부 요소를 통제하기 위해 사용하는 변수

### 3.2 변수 관계의 종류
---

- 인과관계: 독립변수와 종속변수의 기본적 관계, 변수가 다른 변수의 원인이 되는 영향
- 상관관계: 변수 간의 관련성이 존재하는 관계, 인과관계의 상위개념
- 독립관계: 변수 간 상관성, 즉 상관계수가 0인 관계
- 의사관계: 변수 간 상관성은 있지만, 그 상관성이 다른 변수에 의해 나타나는 관계 (ex. 일별 아이스크림 판매량과 익사사고 발생 수의 상관관계의 원인은 '기온'이라는 제3의 변수와의 관계 때문, 기온이 오를 때 아이스크림 판매량과 물놀이를 가는 사람의 수가 동시에 증가하기 때문이다.)
- 양방향적 인과관계: 두 변수가 서로 간에 인과적 영향을 미치는 관계(초기투자 → 매출액 증가 → 후기투자 → 매출액 증가가)
- 조절관계: 독립변수와 종속변수 사이에서 강하고 불확정적인 영향을 미치는 관계
- 매개관계: 독립변수와 종속변수의 중간에서 매개변수가 개입되어 독립변수의 영향을 종속변수에 전달하는 관계 

#### 🔍 조절관계 vs 매개관계

```
조절관계는 제3의 변수가 두 변수 사이 관계의 강도나 방향을 바꾸는 것이고,
매개관계는 제3의 변수가 두 변수 사이의 영향을 전달하거나 설명하는 역할을 하는 것이다.
```

### 3.3 척도의 종류
---
- 척도: 측정하고자 하는 대상을 수치화하는 것에 사용되는 일종의 측정 도구

| 척도 종류   | 구분 가능(명명) | 순서 정보 | 간격 정보 | 절대 0 존재 | 예시                         |
|------------|---------------|-----------|-----------|------------|------------------------------|
| 명명척도   | ✅             | ❌         | ❌         | ❌          | 성별, 지역, 혈액형            |
| 서열척도   | ✅             | ✅         | ❌         | ❌          | 학년, 성적 순위, 만족도       |
| 등간척도   | ✅             | ✅         | ✅         | ❌          | 온도(℃), 지능지수(IQ)         |
| 비율척도   | ✅             | ✅         | ✅         | ✅          | 키, 몸무게, 나이, 소득         |

#### 🔍 변수의 척도에 따른 분석 방법
![image](whatiddone/Statistics_Study/image/3-5.png)

# 04. 데이터의 기술 통계적 측정

```
✅ 학습 목표 :
* 산포도의 의미를 설명하고 측정방법을 나열할 수 있다.
* 정규분포의 왜도값과 첨도값이 얼마인지 답할 수 있다.
```

<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->

### 4.1 중심 성향의 측정
---

- 평균값
    - 산술평균: 전체 변숫값의 합 / 값들의 개수
        - $\bar{x} = \dfrac{1}{n} \sum_{i=1}^{n} x_i$
    - 가중평균: 관측치 수를 고려해 구하는 평균값
        - $\bar{x}_w = \dfrac{\sum_{i=1}^{n} w_i x_i}{\sum_{i=1}^{n} w_i}$
    - 기하평균: 시간에 따라 `비율적으로 변화하는 값`의 평균을 구할 때 사용(`비율의 평균`)
        - $G = \left( \prod_{i=1}^{n} x_i \right)^{\dfrac{1}{n}}$
        - 물가상승률, 인구 변동률, 증권 수익률 등등
    - 조화평균: 시간적으로 변화하는 데이터에서 `평균`을 측정하는 방법을 구할 때 사용(`값의 평균`)
        - $H = \dfrac{n}{\sum_{i=1}^{n} \dfrac{1}{x_i}}$
        - 이동 평균 속도 계산, PER(주가수익비율) 평균 계산, 평균 단가 계산


- 중앙값: 데이터를 내림차순으로 나열했을 때 중앙에 위치한 값
- 최빈값: 데이터 중 가장 빈도가 높은 값


### 4.2 분산과 표준편차
---

- 분산: 편차를 제곱해 평균낸 값
- 표준편차: 분산의 제곱근 값을 구해 실제 편차의 규모와 유사하게 조정한 것   
* 표본의 경우에는 분산을 구할 때 관측치의 수(N)이 아닌 자유도 (n-1)로 나눠줘야 한다
    * 자유도: 자유롭게 선택할 수 있는 숫자의 개수
 
### 4.3 산포도와 범위, 사분위수, 변동계수
---

- 산포도(분산도): 대푯값을 중심으로 자료들이 흩어져 있는 정도
    - 측정방법
        - 범위: 최솟값부터 최댓값까지지
        - 분산
        - 표준편차
        - 사분위수(1사분위수~3사분위수: IQR)
        - 변동계수: (표준편차/산술평균)

### 4.4 왜도와 첨도
---
#### 왜도: 데이터 분포의 좌우 비대칭도

| 구분      | 분포 모습          | 관계|
|-----------|---------|----------|
| 양의 왜도 | 오른쪽 꼬리 길다 (고소득자 등) | 평균 > 중앙값 > 최빈값        |
| 음의 왜도 | 왼쪽 꼬리 길다 (낙제 점수 등)  | 평균 < 중앙값 < 최빈값        |


- 피어슨 비대칭 걔수: 왜도를 측정하는 방법   
    : 평균값, 중앙값, 최빈값 간의 차이를 비교한 후, 그 차이를 표준편차로 나눈 값

    $$3(평균값-중앙값)\over {표본의 표준편차}$$
    $$or$$
    $$3(평균값-최빈빈값)\over {표본의 표준편차}$$

- 보통 0보다 작거나 3보다 크면 데이터가 정규성을 가지지 않는다고 판단함!

#### 첨도: 분포가 정규분포보다 얼마나 뾰족하거나 완만한지의 정도를 나타내는 척도
| 구분      | 분포 모습                                | 특징                                 |
|-----------|-----------------------------------------|--------------------------------------|
| 양의 첨도 | 뾰족한 분포 (꼬리가 두껍고 극단값 많음)  | 중심 집중 ↑, 꼬리 두꺼움 (Leptokurtic) |
| 음의 첨도 | 평평한 분포 (꼬리가 얇고 극단값 적음)    | 중심 집중 ↓, 꼬리 얇음 (Platykurtic)  |

- 정규분포의 첨도 기준이 0일 경우에는 첨도가 음수로 작을수록 분포는 넓게 퍼져있고, 양수로 클수록 뾰족하다.

- 첨도 공식식
$$K = \dfrac{\dfrac{1}{n} \sum_{i=1}^{n} (x_i - \bar{x})^4}{s^4}$$

- $K$: 첨도 값
- $n$: 데이터 개수
- $x_i$: 각 관측값
- $\bar{x}$: 평균
- $s$: 표본 표준편차

✅ 참고: 정규분포의 첨도는 3이며, **K - 3**을 계산해  
- **양의 첨도(Leptokurtic)**: 꼬리가 두꺼움
- **음의 첨도(Platykurtic)**: 꼬리가 얇음

### 4.5 표준편차의 경험법칙
---

- 경험법칙: 정규분포에서 표준편차를 통해 데이터 값들의 범위를 가늠하는 것

데이터의 약 99.7%가 평균으로부터 ±3 표준편차 이내에 속하기 때문에 데이터의 최댓값과 최솟값을 추정할 수 있다.
- 최댓값: 평균 + 3표준편차
- 최솟값: 평균 - 3표준편차
- 데이터의 범위: 6표준편차   
- 표준편차의 근삿값: (범위/6)  

❗️ 하지만 경험법칙은 통계적으로 표본의 크기가 최소 100 이상은 되어야 성립   
- 30~100일 때 표준편차의 근삿값 : 범위/4
- 30 미만: 유의미한 범위 측정 불가
- 정규분포가 아니거나 분포를 모를 경우: 체비셰프의 정리 적용 

#### 🔍 체비셰프의 정리
- 어떤 분포든 평균에서 k배 표준편차 이내에 전체 데이터의 최소 1 - 1/k²이 존재한다.
$$
P\left( |X - \mu| < k\sigma \right) \geq 1 - \frac{1}{k^2}
$$

    - k = 2 → 전체 데이터의 최소 75%

    - k = 3 → 전체 데이터의 최소 88.89%

    - k = 4 → 전체 데이터의 최소 93.75%


# 05. 확률과 확률변수

```
✅ 학습 목표 :
* 확률변수의 개념과 종류를 설명할 수 있다.
* 심슨의 역설을 설명하고, 발생 원인을 식별하며, 이를 해결하기 위한 방안을 도출할 수 있다.
```

<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->
### 5.1 확률의 기본개념
---
#### 확률: 일정한 조건 안에서 특정 사건이 일어날 수 있는 가능성의 정도
#### 표본공간: 통계적 실험을 통해 발생할 수 있는 모든 사건의 집합

### 5.2 확률의 종류
---
#### 비조건 확률(한계확률)
아무런 조건이 없는 상황에서 일어날 확률

#### 결합확률
표본공간 안에서 일어나는 사건 각각의 조합으로 이루어지는 확률(교집합)

#### 조건부 확률
하나의 사건이 먼저 발생했다는 조건이 전제된 상황에서 또 다른 사건이 발생할 확률

### 5.3 분할과 베이지안 이론
---
#### 분할
사건들을 모두 합했을 떄, 전체 사건을 포괄하되, 중복이 일어나지 않는 사건들의 집합<br>
주사위를 던졌을 때, 짝수가 나오는 사건 & 홀수가 나오는 사건

#### 베이지안 이론

어떤 사건 A가 주어졌을 때, 사건 B가 일어날 확률을 계산하는 공식:

$$
P(B|A) = \frac{P(A|B) \cdot P(B)}{P(A)}
$$


새로운 증거 \( A \)가 관측되었을 때, 기존 믿음(사전 확률)을 수정해 **최종 확률(사후 확률)**을 계산한다.<br>
불확실한 상황에서 점진적으로 정보를 업데이트하는 과정의 핵심 원리<br>
`사전확률 -> 새로운 정보(우도 확률) -> 베이즈 정리의 응용 -> 사후확률`

#### 🔍 질병의 발생률과 양성 진단의 정확도에 따른 분류
![image](whatiddone/Statistics_Study/image/5-4.png)

### 5.4 확률변수의 개념과 종류
---
#### 확률변수
측정 값이 변할 수 있는 확률이 주어진 변수(표본평균, 표본분산 등)
    - 이산확률변수: 변수가 가질 수 있는 값이 셀 수 있는 실숫값
    - 연속확률변수: 변수가 가질 수 있는 값이 연속형 값 
        - 특정 구간이 나올 수 있는 확률을 구하는 식으로 접근

### 5.5 심슨의 역설
---
#### 심슨의 역설
하위 집단에서의 경향과 전체 집단에서의 경향이 반대가 되는 통계적 현상으로, 데이터의 정보가 확률 속에 `압축`된 것이라는 확률의 특성을 고려하지 않아 발생

#### 📌 심슨의 역설 사례: UC 버클리 입학 차별 사건 (1973년)

✅ 사건 개요
- 1973년, UC 버클리 대학원 입학 결과에서 **남성 지원자의 합격률이 여성 지원자보다 훨씬 높게 나타남**
- → "여성 차별 의혹"이 제기됨

| 성별 | 지원자 수 | 합격자 수 | 합격률 |
|-----|---------|---------|-------|
| 남성 | 8,442   | 3,714   | 44%   |
| 여성 | 4,321   | 1,270   | 29%   |


✅ 역설 발생 원인
- 전체 합격률만 보면 **남성 합격률이 더 높음 → 여성 차별처럼 보임**
- 그러나 **학과별로 분석해보면**:
  - 여성 지원자가 **합격률이 낮은 학과(경쟁 치열한 학과)에 많이 지원**
  - 남성 지원자는 **합격률 높은 학과에도 고르게 지원**

✅ 핵심 정리
- **전체 데이터**에서는 여성 차별처럼 보였지만
- **학과별로 보면** 여성 합격률이 더 높은 곳도 존재
- 실제로는 **여성이 경쟁이 치열한 학과를 선호해 지원**한 결과
<br>
<br>

# 확인 문제

## 문제 1.

> **🧚Q. 한 대형 병원이 두 명의 외과 의사(A와 B)의 수술 성공률을 비교하려고 한다. 과거 1년간의 데이터를 보면, A 의사의 전체 수술 성공률은 80%, B 의사의 전체 수술 성공률은 90%였다. 이 데이터를 본 병원 경영진은 A 의사의 실력이 B 의사보다 별로라고 판단하여 A 의사의 수술 기회를 줄이는 방향으로 정책을 조정하려 한다.
그러나 일부 의료진은 이 결론에 의문을 제기했다.
그들은 "단순한 전체 성공률이 아니라 더 세부적인 데이터를 분석해야 한다"고 주장했다.**

> **-A 의사의 실력이 실제로 B 의사보다 별로라고 결론짓는 것이 타당한가?   
-그렇지 않다면, 추가로 확인해야 할 정보는 무엇인가?**

<!--심슨의 역설을 이해하였는지 확인하기 위한 문제입니다-->

<!--학습한 개념을 활용하여 자유롭게 설명해 보세요. 구체적인 예시를 들어 설명하면 더욱 좋습니다.-->

```
전체 수술 성공률만으로 의사 A,B 간의 실력을 결정짓는 것은 타당하지 않다. A 의사와 B 의사가 어떤 수술을 진행했는지, 각각 몇 건의 수술을 진행하였는지 그리고 수술 당시 환자의 상태는 어땠는지 등의 세부 데이터를 통해 의사의 실력을 평가하여야 한다.
```

### 🎉 수고하셨습니다.
